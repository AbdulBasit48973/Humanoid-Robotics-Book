<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module4/human-robot-interaction" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Human-Robot Interaction | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/module4/human-robot-interaction"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Human-Robot Interaction | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Overview"><meta data-rh="true" property="og:description" content="Overview"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/module4/human-robot-interaction"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/module4/human-robot-interaction" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/module4/human-robot-interaction" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Human-Robot Interaction","item":"https://your-docusaurus-site.example.com/docs/module4/human-robot-interaction"}]}</script><link rel="stylesheet" href="/assets/css/styles.479a17d7.css">
<script src="/assets/js/runtime~main.97f25e17.js" defer="defer"></script>
<script src="/assets/js/main.c6d5ead6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Documentation</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/your-username/humanoid-robotics-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/intro"><span title="Introduction" class="categoryLinkLabel_W154">Introduction</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module1/intro"><span title="Module 1: ROS 2 - Robotic Nervous System" class="categoryLinkLabel_W154">Module 1: ROS 2 - Robotic Nervous System</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module2/intro"><span title="Module 2: Digital Twins - Gazebo &amp; Unity" class="categoryLinkLabel_W154">Module 2: Digital Twins - Gazebo &amp; Unity</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module3/intro"><span title="Module 3: AI-Robot Brain - NVIDIA Isaac &amp; Nav2" class="categoryLinkLabel_W154">Module 3: AI-Robot Brain - NVIDIA Isaac &amp; Nav2</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/module4/intro"><span title="Module 4: Vision-Language-Action (VLA) Systems" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA) Systems</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4/intro"><span title="Module 4: Vision-Language-Action (VLA) Systems" class="linkLabel_WmDU">Module 4: Vision-Language-Action (VLA) Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4/vision-systems"><span title="Vision Systems" class="linkLabel_WmDU">Vision Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4/language-integration"><span title="Language Integration" class="linkLabel_WmDU">Language Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4/action-planning"><span title="Action Planning" class="linkLabel_WmDU">Action Planning</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/module4/human-robot-interaction"><span title="Human-Robot Interaction" class="linkLabel_WmDU">Human-Robot Interaction</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/capstone/project-ideas"><span title="Capstone Projects" class="categoryLinkLabel_W154">Capstone Projects</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA) Systems</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Human-Robot Interaction</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Human-Robot Interaction</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>This document covers human-robot interaction design principles and implementation techniques for collaborative robotics. Human-robot interaction (HRI) is fundamental to the success of humanoid robots, as these systems are specifically designed to operate in human environments and interact naturally with human users. Effective HRI enables robots to understand human intentions, communicate their own intentions clearly, and coordinate activities safely and efficiently with humans.</p>
<p>Human-robot interaction for humanoid robots must address the unique challenges of operating in human social spaces, where robots must follow social conventions, respect personal space, and communicate in ways that are natural and intuitive for humans. This requires understanding of social signals, appropriate timing for interactions, and the ability to adapt to different social contexts and user preferences.</p>
<p>The multimodal nature of human communication requires humanoid robots to integrate multiple interaction channels including speech, gesture, gaze, posture, and facial expressions. These modalities must be coordinated to create coherent and natural interactions that feel comfortable to human users.</p>
<p>Trust and acceptance are crucial factors in successful human-robot interaction, requiring robots to be predictable, reliable, and transparent in their behavior. Users must understand what the robot is doing and why, and be confident that the robot will behave safely and appropriately in various situations.</p>
<p>Social cognition capabilities enable humanoid robots to understand and respond to human social behavior, including recognizing emotions, interpreting social signals, and adapting their behavior based on social context. These capabilities are essential for natural and effective interaction in social environments.</p>
<p>The design of human-robot interaction must consider the diverse needs and capabilities of different user groups, including people with varying technical expertise, physical abilities, and cultural backgrounds. Inclusive design principles ensure that interaction systems are accessible and usable by the broadest possible range of users.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="multimodal-interaction-systems">Multimodal Interaction Systems<a href="#multimodal-interaction-systems" class="hash-link" aria-label="Direct link to Multimodal Interaction Systems" title="Direct link to Multimodal Interaction Systems" translate="no">​</a></h2>
<p>Multimodal interaction systems integrate multiple communication channels to enable rich and natural human-robot interaction. These systems leverage the complementary strengths of different modalities to create more robust and intuitive interaction experiences.</p>
<p>Speech-based interaction provides the primary channel for complex information exchange and natural communication. For humanoid robots, speech systems must handle both speech recognition for understanding human input and speech synthesis for robot output, with attention to naturalness, clarity, and appropriate timing in conversation.</p>
<p>Gestural interaction allows humans and robots to communicate through body movements and spatial relationships. Humanoid robots can use gestures to indicate objects, show intentions, or emphasize speech, while also recognizing and interpreting human gestures to understand user intentions.</p>
<p>Gaze and attention systems enable robots to establish and maintain appropriate eye contact, show where their attention is focused, and understand where humans are looking to infer their intentions. Gaze behavior is crucial for establishing social connection and understanding attention in collaborative tasks.</p>
<p>Facial expression systems provide important emotional and social communication channels. Humanoid robots can use facial expressions to convey their internal state, emotions, and intentions, while also recognizing human facial expressions to understand user emotional states and social signals.</p>
<p>Tactile interaction through touch enables close-proximity communication and collaboration, particularly important for guidance, assistance, and intimate interaction scenarios. Tactile sensing also provides important feedback for manipulation and navigation tasks.</p>
<p>Proxemic behavior governs the appropriate use of personal space and social distance in human-robot interaction. Humanoid robots must understand and respect human spatial preferences while positioning themselves appropriately for different types of interaction.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="social-robotics-principles">Social Robotics Principles<a href="#social-robotics-principles" class="hash-link" aria-label="Direct link to Social Robotics Principles" title="Direct link to Social Robotics Principles" translate="no">​</a></h2>
<p>Social robotics principles guide the design of robots that can interact effectively in human social environments. These principles draw from social psychology, human factors, and communication theory to create robots that are socially acceptable and effective collaborators.</p>
<p>Anthropomorphic design principles consider how human-like characteristics should be incorporated into robot design to enhance interaction while avoiding the uncanny valley effect. The appropriate level of anthropomorphism depends on the specific application and user population.</p>
<p>Social presence refers to the robot&#x27;s ability to be perceived as a social entity rather than just a machine. This involves consistent behavior, appropriate responses to social cues, and the ability to maintain social relationships over time.</p>
<p>Social norms and conventions require humanoid robots to follow appropriate social behaviors such as turn-taking in conversation, appropriate greetings, and respect for cultural differences. These behaviors help robots integrate naturally into human social environments.</p>
<p>Theory of mind capabilities enable robots to understand that humans have beliefs, desires, and intentions that may differ from their own. This understanding is crucial for effective collaboration and communication.</p>
<p>Social learning allows robots to acquire appropriate social behaviors through observation and interaction with humans, adapting their behavior to match social expectations and cultural norms.</p>
<p>Social acceptance depends on the robot&#x27;s ability to behave in ways that are perceived as appropriate, safe, and beneficial by human users. This includes transparency in behavior, predictability, and respect for human autonomy and dignity.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="safety-and-trust-in-human-robot-interaction">Safety and Trust in Human-Robot Interaction<a href="#safety-and-trust-in-human-robot-interaction" class="hash-link" aria-label="Direct link to Safety and Trust in Human-Robot Interaction" title="Direct link to Safety and Trust in Human-Robot Interaction" translate="no">​</a></h2>
<p>Safety in human-robot interaction encompasses both physical safety and psychological comfort. Physical safety requires that robots operate without causing harm to humans, while psychological safety involves creating interactions that are comfortable and non-threatening.</p>
<p>Risk assessment and mitigation strategies identify potential safety hazards in human-robot interaction and implement appropriate safeguards. For humanoid robots, this includes collision avoidance, force limiting, and emergency stop capabilities.</p>
<p>Predictability and transparency are crucial for safety, as users must be able to anticipate robot behavior and understand the robot&#x27;s intentions. This includes clear communication of the robot&#x27;s state and planned actions.</p>
<p>Trust calibration ensures that users have appropriate levels of trust in the robot - neither over-trusting nor under-trusting its capabilities. This involves accurate representation of robot capabilities and limitations.</p>
<p>Fail-safe mechanisms ensure that robots can handle failures gracefully without causing harm or creating dangerous situations. This includes fallback behaviors and graceful degradation of capabilities.</p>
<p>Consent and autonomy respect the human user&#x27;s right to control the interaction and make decisions about robot behavior. This includes the ability to stop or modify robot actions when desired.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="user-experience-design-for-robotics">User Experience Design for Robotics<a href="#user-experience-design-for-robotics" class="hash-link" aria-label="Direct link to User Experience Design for Robotics" title="Direct link to User Experience Design for Robotics" translate="no">​</a></h2>
<p>User experience design for robotics adapts traditional UX principles to the unique challenges of physical, interactive systems that operate in complex environments. The design process must consider the physical, cognitive, and emotional aspects of human-robot interaction.</p>
<p>Interaction design patterns for robotics define common approaches to specific interaction challenges, such as how to initiate interaction, how to request user input, and how to provide feedback about robot state and intentions.</p>
<p>Feedback design in robotics must provide clear information about robot state, progress toward goals, and any issues or errors that occur. This feedback can be visual, auditory, or haptic, and must be designed to be noticeable but not overwhelming.</p>
<p>Accessibility considerations ensure that robot interaction is usable by people with diverse abilities and needs, including those with visual, auditory, or motor impairments. This may involve alternative interaction modalities or adjustable interface parameters.</p>
<p>Cultural considerations in HRI design recognize that interaction preferences and social norms vary across cultures. Robots deployed in different cultural contexts may need to adapt their behavior and interaction styles accordingly.</p>
<p>Evaluation and testing of human-robot interaction systems require specialized methodologies that can assess both objective performance metrics and subjective user experience measures. These evaluations must often be conducted in realistic environments with actual users.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="interaction-design">Interaction Design<a href="#interaction-design" class="hash-link" aria-label="Direct link to Interaction Design" title="Direct link to Interaction Design" translate="no">​</a></h2>
<ul>
<li class="">Multimodal interaction systems integrating speech, gesture, gaze, and tactile communication</li>
<li class="">Social robotics principles including anthropomorphic design and social presence</li>
<li class="">Safety and trust mechanisms with risk assessment and fail-safe behaviors</li>
<li class="">User experience design with accessibility and cultural considerations</li>
<li class="">Proxemic behavior and spatial interaction management</li>
<li class="">Social learning and adaptation mechanisms for improved interaction</li>
<li class="">Evaluation methodologies for human-robot interaction systems</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/your-username/humanoid-robotics-book/tree/main/docs/module4/human-robot-interaction.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/module4/action-planning"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Action Planning</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/capstone/project-ideas"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Capstone Project Ideas</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#multimodal-interaction-systems" class="table-of-contents__link toc-highlight">Multimodal Interaction Systems</a></li><li><a href="#social-robotics-principles" class="table-of-contents__link toc-highlight">Social Robotics Principles</a></li><li><a href="#safety-and-trust-in-human-robot-interaction" class="table-of-contents__link toc-highlight">Safety and Trust in Human-Robot Interaction</a></li><li><a href="#user-experience-design-for-robotics" class="table-of-contents__link toc-highlight">User Experience Design for Robotics</a></li><li><a href="#interaction-design" class="table-of-contents__link toc-highlight">Interaction Design</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Introduction</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Book. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>